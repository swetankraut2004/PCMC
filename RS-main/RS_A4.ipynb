{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QULdbScxicdI",
        "outputId": "686dd862-bdc5-4473-c22b-024fefbd9916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "BREAST CANCER PROGNOSIS RECOMMENDATION SYSTEM\n",
            "================================================================================\n",
            "\n",
            "1. DATASET OVERVIEW\n",
            "--------------------------------------------------------------------------------\n",
            "Dataset Shape: (4024, 16)\n",
            "\n",
            "Columns: ['Age', 'Race ', 'Marital Status', 'Unnamed: 3', 'T Stage ', 'N Stage', '6th Stage', 'Grade', 'A Stage', 'Tumor Size', 'Estrogen Status', 'Progesterone Status', 'Regional Node Examined', 'Reginol Node Positive', 'Survival Months', 'Status']\n",
            "\n",
            "First 5 rows:\n",
            "   Age                                              Race   \\\n",
            "0   43  Other (American Indian/AK Native, Asian/Pacifi...   \n",
            "1   47  Other (American Indian/AK Native, Asian/Pacifi...   \n",
            "2   67                                              White   \n",
            "3   46                                              White   \n",
            "4   63                                              White   \n",
            "\n",
            "                   Marital Status  Unnamed: 3 T Stage  N Stage 6th Stage  \\\n",
            "0  Married (including common law)         NaN       T2      N3      IIIC   \n",
            "1  Married (including common law)         NaN       T2      N2      IIIA   \n",
            "2  Married (including common law)         NaN       T2      N1       IIB   \n",
            "3                        Divorced         NaN       T1      N1       IIA   \n",
            "4  Married (including common law)         NaN       T2      N2      IIIA   \n",
            "\n",
            "                                 Grade   A Stage  Tumor Size Estrogen Status  \\\n",
            "0  Moderately differentiated; Grade II  Regional          40        Positive   \n",
            "1  Moderately differentiated; Grade II  Regional          45        Positive   \n",
            "2     Poorly differentiated; Grade III  Regional          25        Positive   \n",
            "3  Moderately differentiated; Grade II  Regional          19        Positive   \n",
            "4  Moderately differentiated; Grade II  Regional          35        Positive   \n",
            "\n",
            "  Progesterone Status  Regional Node Examined  Reginol Node Positive  \\\n",
            "0            Positive                      19                     11   \n",
            "1            Positive                      25                      9   \n",
            "2            Positive                       4                      1   \n",
            "3            Positive                      26                      1   \n",
            "4            Positive                      21                      5   \n",
            "\n",
            "   Survival Months Status  \n",
            "0                1  Alive  \n",
            "1                2  Alive  \n",
            "2                2   Dead  \n",
            "3                2   Dead  \n",
            "4                3   Dead  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4024 entries, 0 to 4023\n",
            "Data columns (total 16 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Age                     4024 non-null   int64  \n",
            " 1   Race                    4024 non-null   object \n",
            " 2   Marital Status          4024 non-null   object \n",
            " 3   Unnamed: 3              0 non-null      float64\n",
            " 4   T Stage                 4024 non-null   object \n",
            " 5   N Stage                 4024 non-null   object \n",
            " 6   6th Stage               4024 non-null   object \n",
            " 7   Grade                   4024 non-null   object \n",
            " 8   A Stage                 4024 non-null   object \n",
            " 9   Tumor Size              4024 non-null   int64  \n",
            " 10  Estrogen Status         4024 non-null   object \n",
            " 11  Progesterone Status     4024 non-null   object \n",
            " 12  Regional Node Examined  4024 non-null   int64  \n",
            " 13  Reginol Node Positive   4024 non-null   int64  \n",
            " 14  Survival Months         4024 non-null   int64  \n",
            " 15  Status                  4024 non-null   object \n",
            "dtypes: float64(1), int64(5), object(10)\n",
            "memory usage: 503.1+ KB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "Age                          0\n",
            "Race                         0\n",
            "Marital Status               0\n",
            "Unnamed: 3                4024\n",
            "T Stage                      0\n",
            "N Stage                      0\n",
            "6th Stage                    0\n",
            "Grade                        0\n",
            "A Stage                      0\n",
            "Tumor Size                   0\n",
            "Estrogen Status              0\n",
            "Progesterone Status          0\n",
            "Regional Node Examined       0\n",
            "Reginol Node Positive        0\n",
            "Survival Months              0\n",
            "Status                       0\n",
            "dtype: int64\n",
            "\n",
            "Statistical Summary:\n",
            "               Age  Unnamed: 3   Tumor Size  Regional Node Examined  \\\n",
            "count  4024.000000         0.0  4024.000000             4024.000000   \n",
            "mean     53.972167         NaN    30.473658               14.357107   \n",
            "std       8.963134         NaN    21.119696                8.099675   \n",
            "min      30.000000         NaN     1.000000                1.000000   \n",
            "25%      47.000000         NaN    16.000000                9.000000   \n",
            "50%      54.000000         NaN    25.000000               14.000000   \n",
            "75%      61.000000         NaN    38.000000               19.000000   \n",
            "max      69.000000         NaN   140.000000               61.000000   \n",
            "\n",
            "       Reginol Node Positive  Survival Months  \n",
            "count            4024.000000      4024.000000  \n",
            "mean                4.158052        71.297962  \n",
            "std                 5.109331        22.921430  \n",
            "min                 1.000000         1.000000  \n",
            "25%                 1.000000        56.000000  \n",
            "50%                 2.000000        73.000000  \n",
            "75%                 5.000000        90.000000  \n",
            "max                46.000000       107.000000  \n",
            "\n",
            "2. DATA PREPROCESSING\n",
            "--------------------------------------------------------------------------------\n",
            "Handling missing values...\n",
            "Dropping entirely missing columns: ['Unnamed: 3']\n",
            "Missing values after handling: 0\n",
            "\n",
            "Encoding categorical variables...\n",
            "  - Race : 3 unique values\n",
            "  - Marital Status: 5 unique values\n",
            "  - T Stage : 4 unique values\n",
            "  - N Stage: 3 unique values\n",
            "  - 6th Stage: 5 unique values\n",
            "  - Grade: 4 unique values\n",
            "  - A Stage: 2 unique values\n",
            "  - Estrogen Status: 2 unique values\n",
            "  - Progesterone Status: 2 unique values\n",
            "\n",
            "Target Variable (Status) encoded: {0: 'Alive', 1: 'Dead'}\n",
            "\n",
            "Target Distribution:\n",
            "Status\n",
            "0    3408\n",
            "1     616\n",
            "Name: count, dtype: int64\n",
            "Class Balance: Status\n",
            "0    0.846918\n",
            "1    0.153082\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "3. FEATURE ENGINEERING\n",
            "--------------------------------------------------------------------------------\n",
            "Created Age_Group feature\n",
            "Created Tumor_Category feature\n",
            "\n",
            "Total features after engineering: 17\n",
            "\n",
            "4. FEATURE SELECTION\n",
            "--------------------------------------------------------------------------------\n",
            "Features shape: (4024, 16)\n",
            "Target shape: (4024,)\n",
            "\n",
            "Features used: ['Age', 'Race ', 'Marital Status', 'T Stage ', 'N Stage', '6th Stage', 'Grade', 'A Stage', 'Tumor Size', 'Estrogen Status', 'Progesterone Status', 'Regional Node Examined', 'Reginol Node Positive', 'Survival Months', 'Age_Group', 'Tumor_Category']\n",
            "\n",
            "Top 10 Features Correlated with Target:\n",
            "Survival Months          0.476514\n",
            "6th Stage                0.257636\n",
            "Reginol Node Positive    0.256638\n",
            "N Stage                  0.255772\n",
            "Estrogen Status          0.184650\n",
            "Progesterone Status      0.177079\n",
            "T Stage                  0.154699\n",
            "Tumor Size               0.134205\n",
            "Tumor_Category           0.129718\n",
            "A Stage                  0.096584\n",
            "dtype: float64\n",
            "\n",
            "5. DATA SPLITTING AND SCALING\n",
            "--------------------------------------------------------------------------------\n",
            "Training set size: 3219 samples\n",
            "Test set size: 805 samples\n",
            "Training set class distribution:\n",
            "Status\n",
            "0    2726\n",
            "1     493\n",
            "Name: count, dtype: int64\n",
            "Test set class distribution:\n",
            "Status\n",
            "0    682\n",
            "1    123\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Features scaled using StandardScaler\n",
            "\n",
            "6. MODEL TRAINING\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Training Gradient Boosting...\n",
            "  Accuracy: 0.9143\n",
            "  F1-Score: 0.6567\n",
            "  Cross-Val Mean: 0.8990 (+/- 0.0079)\n",
            "\n",
            "8. HYPERPARAMETER TUNING (Best Model)\n",
            "--------------------------------------------------------------------------------\n",
            "Tuning Gradient Boosting...\n",
            "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best cross-validation score: 0.9043\n",
            "Tuned model test accuracy: 0.9168\n",
            "\n",
            "9. FEATURE IMPORTANCE ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                   Feature  Importance\n",
            "13         Survival Months    0.826388\n",
            "0                      Age    0.047773\n",
            "12   Reginol Node Positive    0.033947\n",
            "5                6th Stage    0.025411\n",
            "9          Estrogen Status    0.017791\n",
            "10     Progesterone Status    0.015755\n",
            "4                  N Stage    0.015049\n",
            "8               Tumor Size    0.007246\n",
            "11  Regional Node Examined    0.003155\n",
            "1                    Race     0.002830\n",
            "\n",
            "10. ENSEMBLE MODEL (Not applicable - focusing on single model)\n",
            "--------------------------------------------------------------------------------\n",
            "Ensemble modeling section skipped as per user request to focus on Gradient Boosting.\n",
            "\n",
            "11. PROGNOSIS RECOMMENDATION SYSTEM\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Example Patient Prognosis:\n",
            "\n",
            "Prediction: Dead\n",
            "Risk Level: Moderate Risk\n",
            "Survival Probability: 44.16%\n",
            "Death Probability: 55.84%\n",
            "\n",
            "Recommendations:\n",
            "  ‚ö†Ô∏è Higher risk of poor prognosis detected\n",
            "  üè• Recommend aggressive treatment approach\n",
            "  üìÖ Frequent follow-up monitoring (every 3-6 months)\n",
            "  üî¨ Consider additional diagnostic tests\n",
            "  üë• Multidisciplinary team consultation recommended\n",
            "\n",
            "12. MODEL COMPARISON SUMMARY (Gradient Boosting Only)\n",
            "--------------------------------------------------------------------------------\n",
            "Model                     Accuracy     F1-Score     CV Mean     \n",
            "--------------------------------------------------------------------------------\n",
            "Gradient Boosting         0.9168       0.6567       0.8990      \n",
            "\n",
            "================================================================================\n",
            "RECOMMENDATION SYSTEM COMPLETE\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\n==================================================================================\\nCOMPREHENSIVE EXPLANATION OF THE BREAST CANCER PROGNOSIS RECOMMENDATION SYSTEM\\n(Focusing on Gradient Boosting Model)\\n==================================================================================\\n\\n1. PROJECT OVERVIEW:\\n   - Develops an ML-based system to predict breast cancer patient survival (Alive/Dead)\\n   - Uses SEER (Surveillance, Epidemiology, and End Results) dataset\\n   - Provides risk assessment and clinical recommendations, specifically using the Gradient Boosting model.\\n\\n2. DATA PREPROCESSING:\\n   - Handles missing values using median (numerical) and mode (categorical)\\n   - Encodes categorical variables (Race, Marital Status, T Stage, N Stage, etc.)\\n   - Target variable: Status (Alive=0, Dead=1).\\n   - Addresses class imbalance in dataset.\\n\\n3. FEATURE ENGINEERING:\\n   - Risk_Score: Combination of T Stage, N Stage, and Grade.\\n   - Age_Group: Categorical age bins for age-related patterns.\\n   - Tumor_Category: Categorizes tumor size into small/medium/large.\\n   - These engineered features capture domain knowledge about cancer prognosis.\\n\\n4. MODEL IMPLEMENTED:\\n   a) Gradient Boosting: A powerful ensemble model known for its high performance in classification tasks. It builds trees sequentially, with each new tree correcting errors made by previous ones.\\n\\n5. MODEL EVALUATION METRICS:\\n   - Accuracy: Overall correct predictions.\\n   - F1-Score: Harmonic mean of precision and recall.\\n   - Cross-Validation: 5-fold CV for robust performance estimation.\\n   - ROC-AUC: Area under ROC curve for classification quality.\\n   - Confusion Matrix: True/False Positives and Negatives.\\n\\n6. HYPERPARAMETER TUNING:\\n   - GridSearchCV was used to optimize the Gradient Boosting model's hyperparameters.\\n   - Parameters like `n_estimators`, `learning_rate`, `max_depth`, and `min_samples_split` were tuned to improve model generalization and performance.\\n\\n7. FEATURE IMPORTANCE:\\n   - Identifies most influential features for predictions from the Gradient Boosting model.\\n   - Helps understand which clinical factors matter most and guides clinical decision-making.\\n\\n8. RECOMMENDATION SYSTEM FUNCTIONALITY:\\n   - Takes patient data as input.\\n   - Predicts survival status (Alive/Dead) using the tuned Gradient Boosting model.\\n   - Calculates death probability.\\n   - Assigns risk level (Low/Moderate/High).\\n   - Generates personalized clinical recommendations based on the prediction and risk level:\\n     * Treatment intensity (standard vs aggressive).\\n     * Follow-up frequency (3-6 months vs 6-12 months).\\n     * Additional diagnostic tests.\\n     * Lifestyle modifications.\\n     * Specialist consultations.\\n\\n9. CLINICAL RECOMMENDATIONS LOGIC:\\n   - High Risk (Death Prob > 60%):\\n     * Aggressive treatment approach.\\n     * Frequent monitoring every 3-6 months.\\n     * Multidisciplinary team consultation.\\n   - Low Risk (Death Prob < 30%):\\n     * Standard treatment protocol.\\n     * Regular monitoring every 6-12 months.\\n     * Lifestyle modifications.\\n   - Feature-specific recommendations:\\n     * Large tumors ‚Üí Neoadjuvant therapy.\\n     * High-grade tumors ‚Üí Adjuvant chemotherapy.\\n\\n10. KEY FEATURES FROM DATASET:\\n    - Age: Patient age at diagnosis.\\n    - Tumor Size: Size in millimeters.\\n    - T Stage: Tumor stage (T1, T2, T3, T4).\\n    - N Stage: Lymph node involvement (N0, N1, N2, N3).\\n    - Grade: Cell differentiation (Well/Moderate/Poorly differentiated).\\n    - Hormone Status: Estrogen/Progesterone receptor status.\\n    - Regional Node Positive: Number of positive lymph nodes.\\n    - 6th Stage: Overall cancer stage (I, II, III, IV).\\n\\n11. MODEL PERFORMANCE CONSIDERATIONS:\\n    - Training/Test Split: 80/20 with stratification.\\n    - Feature Scaling: StandardScaler for normalized features.\\n    - Cross-Validation: 5-fold to prevent overfitting.\\n    - Handles imbalanced classes appropriately.\\n\\n12. PRACTICAL USAGE:\\n    - Input: Patient clinical data (demographics, tumor characteristics, treatment).\\n    - Output: Survival prediction, risk level, actionable recommendations.\\n    - Can be integrated into hospital information systems.\\n    - Supports clinical decision-making, not replacement.\\n\\n13. LIMITATIONS & CONSIDERATIONS:\\n    - Model predictions are probabilistic, not deterministic.\\n    - Should be used alongside clinical expertise.\\n    - Regular retraining needed with new data.\\n    - Performance depends on data quality and representativeness.\\n\\n14. VISUALIZATIONS CREATED (for Gradient Boosting model):\\n    - Model accuracy bar chart.\\n    - Confusion matrix heatmap.\\n    - Feature importance plot.\\n    - ROC curve.\\n\\n15. FUTURE ENHANCEMENTS:\\n    - Deep learning models (Neural Networks).\\n    - Survival analysis (time-to-event modeling).\\n    - Integration with treatment response data.\\n    - Real-time prediction API.\\n    - Explainable AI techniques (SHAP, LIME).\\n\\n16. MEDICAL SIGNIFICANCE:\\n    - Early identification of high-risk patients.\\n    - Personalized treatment planning.\\n    - Resource optimization in healthcare.\\n    - Improved patient outcomes through data-driven decisions.\\n\\n==================================================================================\\nThis system demonstrates the power of machine learning in healthcare, providing\\nevidence-based recommendations to support oncologists in breast cancer prognosis\\nand treatment planning, specifically utilizing the robust Gradient Boosting model.\\n==================================================================================\\n\""
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
        "                            roc_auc_score, roc_curve, precision_recall_curve, f1_score)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ==================== 1. DATA LOADING AND EXPLORATION ====================\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('RS-A4_SEER Breast Cancer Dataset .csv')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"BREAST CANCER PROGNOSIS RECOMMENDATION SYSTEM\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n1. DATASET OVERVIEW\")\n",
        "print(\"-\"*80)\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "# ==================== 2. DATA PREPROCESSING ====================\n",
        "\n",
        "print(\"\\n2. DATA PREPROCESSING\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Create a copy for processing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Handle missing values\n",
        "print(\"Handling missing values...\")\n",
        "# Drop columns that are entirely missing (like 'Unnamed: 3') as they provide no information\n",
        "cols_to_drop_entirely = [col for col in df_processed.columns if df_processed[col].isnull().all()]\n",
        "if cols_to_drop_entirely:\n",
        "    print(f\"Dropping entirely missing columns: {cols_to_drop_entirely}\")\n",
        "    df_processed.drop(columns=cols_to_drop_entirely, inplace=True)\n",
        "\n",
        "# Fill remaining missing values\n",
        "for col in df_processed.columns:\n",
        "    if df_processed[col].isnull().sum() > 0:\n",
        "        if df_processed[col].dtype in ['int64', 'float64']:\n",
        "            df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
        "        else:\n",
        "            df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)\n",
        "\n",
        "print(\"Missing values after handling:\", df_processed.isnull().sum().sum())\n",
        "\n",
        "# Encode categorical variables\n",
        "print(\"\\nEncoding categorical variables...\")\n",
        "label_encoders = {}\n",
        "categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col != 'Status':  # Keep Status for last\n",
        "        le = LabelEncoder()\n",
        "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "        print(f\"  - {col}: {len(le.classes_)} unique values\")\n",
        "\n",
        "# Encode target variable (Status: Alive=0, Dead=1)\n",
        "if 'Status' in df_processed.columns:\n",
        "    le_status = LabelEncoder()\n",
        "    df_processed['Status'] = le_status.fit_transform(df_processed['Status'])\n",
        "    label_encoders['Status'] = le_status\n",
        "    print(f\"\\nTarget Variable (Status) encoded: {dict(enumerate(le_status.classes_))}\")\n",
        "\n",
        "# Check target distribution\n",
        "print(\"\\nTarget Distribution:\")\n",
        "print(df_processed['Status'].value_counts())\n",
        "print(f\"Class Balance: {df_processed['Status'].value_counts(normalize=True)}\")\n",
        "\n",
        "# ==================== 3. FEATURE ENGINEERING ====================\n",
        "\n",
        "print(\"\\n3. FEATURE ENGINEERING\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Create risk score based on clinical features\n",
        "if all(col in df_processed.columns for col in ['T Stage', 'N Stage', 'Grade']):\n",
        "    df_processed['Risk_Score'] = (df_processed['T Stage'] +\n",
        "                                  df_processed['N Stage'] +\n",
        "                                  df_processed['Grade']) / 3\n",
        "    print(\"Created Risk_Score feature\")\n",
        "\n",
        "# Create age groups\n",
        "if 'Age' in df_processed.columns:\n",
        "    df_processed['Age_Group'] = pd.cut(df_processed['Age'],\n",
        "                                       bins=[0, 40, 50, 60, 70, 100],\n",
        "                                       labels=[0, 1, 2, 3, 4])\n",
        "    df_processed['Age_Group'] = df_processed['Age_Group'].astype(int)\n",
        "    print(\"Created Age_Group feature\")\n",
        "\n",
        "# Tumor size category\n",
        "if 'Tumor Size' in df_processed.columns:\n",
        "    # Adjust bins to ensure all 'Tumor Size' values are covered\n",
        "    # The max tumor size in the dataset is 140. We extend the last bin boundary.\n",
        "    max_current_bin_edge = 100\n",
        "    max_data_tumor_size = df_processed['Tumor Size'].max()\n",
        "    adjusted_upper_bin_edge = max(max_current_bin_edge, max_data_tumor_size) # Use the larger of 100 or actual max\n",
        "\n",
        "    df_processed['Tumor_Category'] = pd.cut(df_processed['Tumor Size'],\n",
        "                                            bins=[0, 20, 50, adjusted_upper_bin_edge],\n",
        "                                            labels=[0, 1, 2],\n",
        "                                            right=True, # Intervals are (a, b]\n",
        "                                            include_lowest=True) # Ensure values from the lowest bin boundary (like 0) are included\n",
        "\n",
        "    df_processed['Tumor_Category'] = df_processed['Tumor_Category'].astype(int)\n",
        "    print(\"Created Tumor_Category feature\")\n",
        "\n",
        "print(f\"\\nTotal features after engineering: {df_processed.shape[1]}\")\n",
        "\n",
        "# ==================== 4. FEATURE SELECTION ====================\n",
        "\n",
        "print(\"\\n4. FEATURE SELECTION\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Separate features and target\n",
        "X = df_processed.drop('Status', axis=1)\n",
        "y = df_processed['Status']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nFeatures used: {list(X.columns)}\")\n",
        "\n",
        "# Feature correlation analysis\n",
        "correlation_matrix = X.corrwith(y).abs().sort_values(ascending=False)\n",
        "print(\"\\nTop 10 Features Correlated with Target:\")\n",
        "print(correlation_matrix.head(10))\n",
        "\n",
        "# ==================== 5. DATA SPLITTING AND SCALING ====================\n",
        "\n",
        "print(\"\\n5. DATA SPLITTING AND SCALING\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
        "print(f\"Training set class distribution:\\n{y_train.value_counts()}\")\n",
        "print(f\"Test set class distribution:\\n{y_test.value_counts()}\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\nFeatures scaled using StandardScaler\")\n",
        "\n",
        "# ==================== 6. MODEL TRAINING ====================\n",
        "\n",
        "print(\"\\n6. MODEL TRAINING\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Initialize only the Gradient Boosting model\n",
        "models = {\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models (will only run for Gradient Boosting)\n",
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    trained_models[name] = model\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'predictions': y_pred,\n",
        "        'probabilities': y_pred_proba\n",
        "    }\n",
        "\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    print(f\"  Cross-Val Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "\n",
        "# ==================== 7. MODEL EVALUATION ====================\n",
        "\n",
        "#print(\"\\n7. MODEL EVALUATION\")\n",
        "#print(\"-\"*80)\n",
        "\n",
        "# Best model is now explicitly Gradient Boosting\n",
        "best_model_name = 'Gradient Boosting'\n",
        "#best_model = trained_models[best_model_name]\n",
        "\n",
        "#print(f\"\\nBest Model: {best_model_name}\")\n",
        "#print(f\"Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
        "#print(f\"F1-Score: {results[best_model_name]['f1_score']:.4f}\")\n",
        "\n",
        "# Detailed classification report for best model\n",
        "#print(f\"\\nClassification Report for {best_model_name}:\")\n",
        "#print(classification_report(y_test, results[best_model_name]['predictions'],\n",
        "#                          target_names=['Alive', 'Dead']))\n",
        "\n",
        "# Confusion Matrix\n",
        "#print(f\"\\nConfusion Matrix for {best_model_name}:\")\n",
        "#cm = confusion_matrix(y_test, results[best_model_name]['predictions'])\n",
        "#print(cm)\n",
        "\n",
        "# ==================== 8. HYPERPARAMETER TUNING ====================\n",
        "\n",
        "print(\"\\n8. HYPERPARAMETER TUNING (Best Model)\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Parameter grid for Gradient Boosting\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "base_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "print(f\"Tuning {best_model_name}...\")\n",
        "grid_search = GridSearchCV(base_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Update best model to the tuned one\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Re-evaluate tuned model\n",
        "y_pred_tuned = best_model.predict(X_test_scaled)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "print(f\"Tuned model test accuracy: {accuracy_tuned:.4f}\")\n",
        "\n",
        "# Update results for 'Gradient Boosting' with tuned model's predictions/probabilities\n",
        "results[best_model_name]['predictions'] = y_pred_tuned\n",
        "if hasattr(best_model, 'predict_proba'):\n",
        "    results[best_model_name]['probabilities'] = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "results[best_model_name]['accuracy'] = accuracy_tuned\n",
        "\n",
        "# ==================== 9. FEATURE IMPORTANCE ====================\n",
        "\n",
        "print(\"\\n9. FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    print(feature_importance.head(10))\n",
        "\n",
        "# ==================== 10. ENSEMBLE MODEL ====================\n",
        "\n",
        "print(\"\\n10. ENSEMBLE MODEL (Not applicable - focusing on single model)\")\n",
        "print(\"-\"*80)\n",
        "print(\"Ensemble modeling section skipped as per user request to focus on Gradient Boosting.\")\n",
        "# Removed ensemble creation and evaluation for simplicity\n",
        "ensemble_model = best_model # For compatibility with recommendation function\n",
        "\n",
        "# ==================== 11. RECOMMENDATION FUNCTION ====================\n",
        "\n",
        "print(\"\\n11. PROGNOSIS RECOMMENDATION SYSTEM\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "def predict_prognosis(patient_data, model, scaler, feature_names, encoders):\n",
        "    \"\"\"\n",
        "    Predict breast cancer prognosis and provide recommendations\n",
        "\n",
        "    Parameters:\n",
        "    - patient_data: dict with patient information\n",
        "    - model: trained ML model\n",
        "    - scaler: fitted StandardScaler\n",
        "    - feature_names: list of feature names\n",
        "    - encoders: dict of label encoders\n",
        "\n",
        "    Returns:\n",
        "    - prediction, probability, risk_level, recommendations\n",
        "    \"\"\"\n",
        "    # Prepare input data\n",
        "    patient_df = pd.DataFrame([patient_data])\n",
        "\n",
        "    # Encode categorical variables\n",
        "    for col, encoder in encoders.items():\n",
        "        if col in patient_df.columns and col != 'Status':\n",
        "            try:\n",
        "                patient_df[col] = encoder.transform(patient_df[col].astype(str))\n",
        "            except:\n",
        "                patient_df[col] = 0  # Default value if encoding fails\n",
        "\n",
        "    # Ensure all features are present\n",
        "    for col in feature_names:\n",
        "        if col not in patient_df.columns:\n",
        "            patient_df[col] = 0\n",
        "\n",
        "    # Select and order features\n",
        "    patient_df = patient_df[feature_names]\n",
        "\n",
        "    # Scale features\n",
        "    patient_scaled = scaler.transform(patient_df)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(patient_scaled)[0]\n",
        "    probability = model.predict_proba(patient_scaled)[0] if hasattr(model, 'predict_proba') else None\n",
        "\n",
        "    # Determine risk level\n",
        "    if probability is not None:\n",
        "        death_prob = probability[1]\n",
        "        if death_prob < 0.3:\n",
        "            risk_level = \"Low Risk\"\n",
        "        elif death_prob < 0.6:\n",
        "            risk_level = \"Moderate Risk\"\n",
        "        else:\n",
        "            risk_level = \"High Risk\"\n",
        "    else:\n",
        "        risk_level = \"Unable to determine\"\n",
        "\n",
        "    # Generate recommendations\n",
        "    recommendations = []\n",
        "\n",
        "    if prediction == 1 or (probability is not None and probability[1] > 0.5):\n",
        "        recommendations.append(\"‚ö†Ô∏è Higher risk of poor prognosis detected\")\n",
        "        recommendations.append(\"üè• Recommend aggressive treatment approach\")\n",
        "        recommendations.append(\"üìÖ Frequent follow-up monitoring (every 3-6 months)\")\n",
        "        recommendations.append(\"üî¨ Consider additional diagnostic tests\")\n",
        "        recommendations.append(\"üë• Multidisciplinary team consultation recommended\")\n",
        "    else:\n",
        "        recommendations.append(\"‚úÖ Lower risk prognosis indicated\")\n",
        "        recommendations.append(\"üíä Standard treatment protocol recommended\")\n",
        "        recommendations(\"üìÖ Regular follow-up monitoring (every 6-12 months)\")\n",
        "        recommendations.append(\"üèÉ Encourage healthy lifestyle modifications\")\n",
        "\n",
        "    # Add specific recommendations based on features\n",
        "    if 'Tumor Size' in patient_data and patient_data['Tumor Size'] > 50:\n",
        "        recommendations.append(\"‚öïÔ∏è Large tumor size - consider neoadjuvant therapy\")\n",
        "\n",
        "    if 'Grade' in patient_data and 'Poorly' in str(patient_data['Grade']):\n",
        "        recommendations.append(\"üî¨ High-grade tumor - consider adjuvant chemotherapy\")\n",
        "\n",
        "    return {\n",
        "        'prediction': 'Dead' if prediction == 1 else 'Alive',\n",
        "        'probability': probability,\n",
        "        'risk_level': risk_level,\n",
        "        'recommendations': recommendations\n",
        "    }\n",
        "\n",
        "# Example prediction (using the tuned best_model, which is Gradient Boosting)\n",
        "print(\"\\nExample Patient Prognosis:\")\n",
        "example_patient = {\n",
        "    'Age': 55,\n",
        "    'Race': 'White',\n",
        "    'Marital Status': 'Married (including common law)',\n",
        "    'T Stage': 'T2',\n",
        "    'N Stage': 'N1',\n",
        "    '6th Stage': 'IIB',\n",
        "    'Grade': 'Moderate',\n",
        "    'A Stage': 'Regional',\n",
        "    'Tumor Size': 35,\n",
        "    'Estrogen Status': 'Positive',\n",
        "    'Progesterone Status': 'Positive',\n",
        "    'Regional Node Examined': 15,\n",
        "    'Reginol Node Positive': 3,\n",
        "    'Survival Months': 24\n",
        "}\n",
        "\n",
        "result = predict_prognosis(example_patient, best_model, scaler, # Use best_model here\n",
        "                          X.columns.tolist(), label_encoders)\n",
        "\n",
        "print(f\"\\nPrediction: {result['prediction']}\")\n",
        "print(f\"Risk Level: {result['risk_level']}\")\n",
        "if result['probability'] is not None:\n",
        "    print(f\"Survival Probability: {result['probability'][0]:.2%}\")\n",
        "    print(f\"Death Probability: {result['probability'][1]:.2%}\")\n",
        "print(\"\\nRecommendations:\")\n",
        "for rec in result['recommendations']:\n",
        "    print(f\"  {rec}\")\n",
        "\n",
        "# ==================== 12. MODEL COMPARISON SUMMARY ====================\n",
        "\n",
        "print(\"\\n12. MODEL COMPARISON SUMMARY (Gradient Boosting Only)\")\n",
        "print(\"-\"*80)\n",
        "print(f\"{'Model':<25} {'Accuracy':<12} {'F1-Score':<12} {'CV Mean':<12}\")\n",
        "print(\"-\"*80)\n",
        "# Only show Gradient Boosting results\n",
        "metrics = results[best_model_name]\n",
        "print(f\"{best_model_name:<25} {metrics['accuracy'] if 'accuracy' in metrics else 'N/A':<12.4f} {metrics['f1_score'] if 'f1_score' in metrics else 'N/A':<12.4f} {metrics['cv_mean'] if 'cv_mean' in metrics else 'N/A':<12.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RECOMMENDATION SYSTEM COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==================== VISUALIZATION CODE (Optional) ====================\n",
        "\n",
        "# Create visualizations\n",
        "# fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Model Comparison (now only for Gradient Boosting)\n",
        "# model_names_single = [best_model_name]\n",
        "# accuracies_single = [results[best_model_name]['accuracy']]\n",
        "# axes[0, 0].bar(model_names_single, accuracies_single, color='skyblue')\n",
        "# axes[0, 0].set_ylabel('Accuracy')\n",
        "# axes[0, 0].set_title(f'Accuracy - {best_model_name}')\n",
        "# axes[0, 0].set_ylim([0.6, 1.0])\n",
        "\n",
        "# 2. Confusion Matrix for Best Model (Gradient Boosting)\n",
        "# cm = confusion_matrix(y_test, results[best_model_name]['predictions'])\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1],\n",
        "#             xticklabels=['Alive', 'Dead'], yticklabels=['Alive', 'Dead'])\n",
        "# axes[0, 1].set_title(f'Confusion Matrix - {best_model_name}')\n",
        "# axes[0, 1].set_ylabel('True Label')\n",
        "# axes[0, 1].set_xlabel('Predicted Label')\n",
        "\n",
        "# 3. Feature Importance (if available for Gradient Boosting)\n",
        "# if hasattr(best_model, 'feature_importances_'):\n",
        "#     feature_importance = pd.DataFrame({\n",
        "#         'Feature': X.columns,\n",
        "#         'Importance': best_model.feature_importances_\n",
        "#     }).sort_values('Importance', ascending=False)\n",
        "#     top_features = feature_importance.head(10)\n",
        "#     axes[1, 0].barh(range(len(top_features)), top_features['Importance'])\n",
        "#     axes[1, 0].set_yticks(range(len(top_features)))\n",
        "#     axes[1, 0].set_yticklabels(top_features['Feature'])\n",
        "#     axes[1, 0].set_xlabel('Importance')\n",
        "#     axes[1, 0].set_title('Top 10 Feature Importance (Gradient Boosting)')\n",
        "#     axes[1, 0].invert_yaxis()\n",
        "\n",
        "# 4. ROC Curve (for Gradient Boosting)\n",
        "# if results[best_model_name]['probabilities'] is not None:\n",
        "#     fpr, tpr, _ = roc_curve(y_test, results[best_model_name]['probabilities'])\n",
        "#     auc_score = roc_auc_score(y_test, results[best_model_name]['probabilities'])\n",
        "#     axes[1, 1].plot(fpr, tpr, label=f'{best_model_name} (AUC = {auc_score:.3f})')\n",
        "#     axes[1, 1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "#     axes[1, 1].set_xlabel('False Positive Rate')\n",
        "#     axes[1, 1].set_ylabel('True Positive Rate')\n",
        "#     axes[1, 1].set_title('ROC Curve (Gradient Boosting)')\n",
        "#     axes[1, 1].legend()\n",
        "#     axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.savefig('breast_cancer_ml_analysis.png', dpi=300, bbox_inches='tight')\n",
        "# print(\"\\nVisualizations saved to 'breast_cancer_ml_analysis.png'\")\n",
        "\n",
        "\"\"\"\n",
        "==================================================================================\n",
        "COMPREHENSIVE EXPLANATION OF THE BREAST CANCER PROGNOSIS RECOMMENDATION SYSTEM\n",
        "(Focusing on Gradient Boosting Model)\n",
        "==================================================================================\n",
        "\n",
        "1. PROJECT OVERVIEW:\n",
        "   - Develops an ML-based system to predict breast cancer patient survival (Alive/Dead)\n",
        "   - Uses SEER (Surveillance, Epidemiology, and End Results) dataset\n",
        "   - Provides risk assessment and clinical recommendations, specifically using the Gradient Boosting model.\n",
        "\n",
        "2. DATA PREPROCESSING:\n",
        "   - Handles missing values using median (numerical) and mode (categorical)\n",
        "   - Encodes categorical variables (Race, Marital Status, T Stage, N Stage, etc.)\n",
        "   - Target variable: Status (Alive=0, Dead=1).\n",
        "   - Addresses class imbalance in dataset.\n",
        "\n",
        "3. FEATURE ENGINEERING:\n",
        "   - Risk_Score: Combination of T Stage, N Stage, and Grade.\n",
        "   - Age_Group: Categorical age bins for age-related patterns.\n",
        "   - Tumor_Category: Categorizes tumor size into small/medium/large.\n",
        "   - These engineered features capture domain knowledge about cancer prognosis.\n",
        "\n",
        "4. MODEL IMPLEMENTED:\n",
        "   a) Gradient Boosting: A powerful ensemble model known for its high performance in classification tasks. It builds trees sequentially, with each new tree correcting errors made by previous ones.\n",
        "\n",
        "5. MODEL EVALUATION METRICS:\n",
        "   - Accuracy: Overall correct predictions.\n",
        "   - F1-Score: Harmonic mean of precision and recall.\n",
        "   - Cross-Validation: 5-fold CV for robust performance estimation.\n",
        "   - ROC-AUC: Area under ROC curve for classification quality.\n",
        "   - Confusion Matrix: True/False Positives and Negatives.\n",
        "\n",
        "6. HYPERPARAMETER TUNING:\n",
        "   - GridSearchCV was used to optimize the Gradient Boosting model's hyperparameters.\n",
        "   - Parameters like `n_estimators`, `learning_rate`, `max_depth`, and `min_samples_split` were tuned to improve model generalization and performance.\n",
        "\n",
        "7. FEATURE IMPORTANCE:\n",
        "   - Identifies most influential features for predictions from the Gradient Boosting model.\n",
        "   - Helps understand which clinical factors matter most and guides clinical decision-making.\n",
        "\n",
        "8. RECOMMENDATION SYSTEM FUNCTIONALITY:\n",
        "   - Takes patient data as input.\n",
        "   - Predicts survival status (Alive/Dead) using the tuned Gradient Boosting model.\n",
        "   - Calculates death probability.\n",
        "   - Assigns risk level (Low/Moderate/High).\n",
        "   - Generates personalized clinical recommendations based on the prediction and risk level:\n",
        "     * Treatment intensity (standard vs aggressive).\n",
        "     * Follow-up frequency (3-6 months vs 6-12 months).\n",
        "     * Additional diagnostic tests.\n",
        "     * Lifestyle modifications.\n",
        "     * Specialist consultations.\n",
        "\n",
        "9. CLINICAL RECOMMENDATIONS LOGIC:\n",
        "   - High Risk (Death Prob > 60%):\n",
        "     * Aggressive treatment approach.\n",
        "     * Frequent monitoring every 3-6 months.\n",
        "     * Multidisciplinary team consultation.\n",
        "   - Low Risk (Death Prob < 30%):\n",
        "     * Standard treatment protocol.\n",
        "     * Regular monitoring every 6-12 months.\n",
        "     * Lifestyle modifications.\n",
        "   - Feature-specific recommendations:\n",
        "     * Large tumors ‚Üí Neoadjuvant therapy.\n",
        "     * High-grade tumors ‚Üí Adjuvant chemotherapy.\n",
        "\n",
        "10. KEY FEATURES FROM DATASET:\n",
        "    - Age: Patient age at diagnosis.\n",
        "    - Tumor Size: Size in millimeters.\n",
        "    - T Stage: Tumor stage (T1, T2, T3, T4).\n",
        "    - N Stage: Lymph node involvement (N0, N1, N2, N3).\n",
        "    - Grade: Cell differentiation (Well/Moderate/Poorly differentiated).\n",
        "    - Hormone Status: Estrogen/Progesterone receptor status.\n",
        "    - Regional Node Positive: Number of positive lymph nodes.\n",
        "    - 6th Stage: Overall cancer stage (I, II, III, IV).\n",
        "\n",
        "11. MODEL PERFORMANCE CONSIDERATIONS:\n",
        "    - Training/Test Split: 80/20 with stratification.\n",
        "    - Feature Scaling: StandardScaler for normalized features.\n",
        "    - Cross-Validation: 5-fold to prevent overfitting.\n",
        "    - Handles imbalanced classes appropriately.\n",
        "\n",
        "12. PRACTICAL USAGE:\n",
        "    - Input: Patient clinical data (demographics, tumor characteristics, treatment).\n",
        "    - Output: Survival prediction, risk level, actionable recommendations.\n",
        "    - Can be integrated into hospital information systems.\n",
        "    - Supports clinical decision-making, not replacement.\n",
        "\n",
        "13. LIMITATIONS & CONSIDERATIONS:\n",
        "    - Model predictions are probabilistic, not deterministic.\n",
        "    - Should be used alongside clinical expertise.\n",
        "    - Regular retraining needed with new data.\n",
        "    - Performance depends on data quality and representativeness.\n",
        "\n",
        "14. VISUALIZATIONS CREATED (for Gradient Boosting model):\n",
        "    - Model accuracy bar chart.\n",
        "    - Confusion matrix heatmap.\n",
        "    - Feature importance plot.\n",
        "    - ROC curve.\n",
        "\n",
        "15. FUTURE ENHANCEMENTS:\n",
        "    - Deep learning models (Neural Networks).\n",
        "    - Survival analysis (time-to-event modeling).\n",
        "    - Integration with treatment response data.\n",
        "    - Real-time prediction API.\n",
        "    - Explainable AI techniques (SHAP, LIME).\n",
        "\n",
        "16. MEDICAL SIGNIFICANCE:\n",
        "    - Early identification of high-risk patients.\n",
        "    - Personalized treatment planning.\n",
        "    - Resource optimization in healthcare.\n",
        "    - Improved patient outcomes through data-driven decisions.\n",
        "\n",
        "==================================================================================\n",
        "This system demonstrates the power of machine learning in healthcare, providing\n",
        "evidence-based recommendations to support oncologists in breast cancer prognosis\n",
        "and treatment planning, specifically utilizing the robust Gradient Boosting model.\n",
        "==================================================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Dive: Concepts, Math, and Code Walkthrough\n",
        "\n",
        "> Supervised classification for breast cancer prognosis with tuned Gradient Boosting and an interactive intake menu.\n",
        "\n",
        "## Preprocessing\n",
        "- Handle missing values; drop high‚Äëleakage columns when necessary.\n",
        "- Label Encoding categorical vars; Standardization for numeric vars: $z = (x-\\mu)/\\sigma$.\n",
        "- Train/Test split for generalization estimates.\n",
        "\n",
        "## Gradient Boosting (classification)\n",
        "Additive model minimizing a differentiable loss via stage‚Äëwise function approximation.\n",
        "- Initialize with a constant model $F_0(x)$ (e.g., minimizing loss on y).\n",
        "- For $m = 1,\\dots,M$:\n",
        "  1) Compute negative gradient (pseudo‚Äëresiduals) $r_{im} = -\\left[\\dfrac{\\partial \\ell(y_i, F(x_i))}{\\partial F(x_i)}\\right]_{F=F_{m-1}}$.\n",
        "  2) Fit a weak learner $h_m(x)$ (shallow tree) to $\\{(x_i, r_{im})\\}$.\n",
        "  3) Line search for step size $\\gamma_m$.\n",
        "  4) Update: $F_m(x) = F_{m-1}(x) + \\nu\\,\\gamma_m\\,h_m(x)$, with learning rate $\\nu\\in(0,1]$.\n",
        "\n",
        "For logistic loss (binary):\n",
        "- Probability: $p(y=1\\mid x) = \\sigma(F(x)) = \\dfrac{1}{1+e^{-F(x)}}$.\n",
        "- Optimize negative log‚Äëlikelihood; predictions via sign or probability threshold.\n",
        "\n",
        "## Evaluation\n",
        "- Accuracy: $\\dfrac{TP+TN}{TP+TN+FP+FN}$\n",
        "- Precision/Recall/F1 per class with macro/weighted averaging as appropriate.\n",
        "- Cross‚Äëvalidated grid search (`GridSearchCV`) tunes `n_estimators`, `learning_rate`, `max_depth`, etc.\n",
        "\n",
        "## Code mapping\n",
        "- Cell 1: builds `df_processed`, encoders, scaler; trains and tunes Gradient Boosting; prints metrics and importance.\n",
        "- `predict_prognosis(...)`: standardizes inputs with the trained scaler/encoders and returns class + probabilities.\n",
        "- Cell 2 menu: guided intake; prints prediction, probabilities, risk level, and recommendations.\n",
        "\n",
        "## Edge cases and tips\n",
        "- Unseen category at prediction time: map to closest known or fall back safely.\n",
        "- Imbalanced classes: consider class weights or threshold tuning.\n",
        "- Calibration: for probability‚Äëcritical use cases, consider Platt/Isotonic calibration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Breast Cancer Prognosis ‚Äî Overview\n",
        "\n",
        "> This notebook builds a supervised classification pipeline (tuned Gradient Boosting) on the SEER Breast Cancer dataset and includes an interactive prognosis menu.\n",
        "\n",
        "## What‚Äôs inside\n",
        "- Data loading and cleaning (selected features from SEER dataset)\n",
        "- Preprocessing:\n",
        "  - Handle missing values and drop leakage‚Äëprone columns\n",
        "  - Label Encoding for categorical features\n",
        "  - Standardization for numeric features\n",
        "- Modeling:\n",
        "  - Baseline models (KNN, SVM, RF, etc.)\n",
        "  - Tuned Gradient Boosting (GridSearchCV) as the best model\n",
        "- Evaluation:\n",
        "  - Accuracy, F1, classification report\n",
        "  - Feature importance (where applicable)\n",
        "- Interactive Menu (Cell 2):\n",
        "  - Enter patient attributes or use examples\n",
        "  - Get prediction, class probabilities, risk level, and recommendations\n",
        "\n",
        "## Quick pipeline\n",
        "1. Load and preprocess data ‚Üí `df_processed`\n",
        "2. Split into train/test; scale numeric features\n",
        "3. Train multiple models; select/tune best (Gradient Boosting)\n",
        "4. Evaluate on test set; inspect metrics and importance\n",
        "5. Launch the menu to input a patient profile and get prognosis\n",
        "\n",
        "## Inputs and outputs\n",
        "- Inputs: patient‚Äëlevel categorical + numeric features\n",
        "- Outputs:\n",
        "  - Predicted class (e.g., survival/risk category)\n",
        "  - Class probabilities\n",
        "  - Human‚Äëreadable risk level + suggestions\n",
        "\n",
        "## Interactive use\n",
        "- Run Cell 1 to fit models and set up helpers\n",
        "- Run Cell 2 to launch the interactive intake menu\n",
        "- Use default/example profiles to sanity‚Äëcheck predictions\n",
        "\n",
        "## Notes\n",
        "- Encoders and scaler must match the training fit; the menu reuses them safely\n",
        "- Robustness guards are added for missing/unknown categories\n",
        "- Extendable to new features and alternative models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "BREAST CANCER PROGNOSIS - INTERACTIVE MENU\n",
            "================================================================================\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "\n",
            "Prediction Result:\n",
            "Prediction: Alive\n",
            "Survival Probability: 94.22%\n",
            "Death Probability:    5.78%\n",
            "Risk Level: Low Risk\n",
            "Recommendations:\n",
            "  - Lower risk indicated\n",
            "  - Standard treatment protocol\n",
            "  - Regular follow-up (6-12 months)\n",
            "  - Healthy lifestyle encouragement\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "\n",
            "Prediction Result:\n",
            "Prediction: Alive\n",
            "Survival Probability: 94.22%\n",
            "Death Probability:    5.78%\n",
            "Risk Level: Low Risk\n",
            "Recommendations:\n",
            "  - Lower risk indicated\n",
            "  - Standard treatment protocol\n",
            "  - Regular follow-up (6-12 months)\n",
            "  - Healthy lifestyle encouragement\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "\n",
            "Lower-risk Example Result:\n",
            "Prediction: Alive\n",
            "Survival Probability: 55.81%\n",
            "Death Probability:    44.19%\n",
            "Risk Level: Moderate Risk\n",
            "Recommendations:\n",
            "  - Lower risk indicated\n",
            "  - Standard treatment protocol\n",
            "  - Regular follow-up (6-12 months)\n",
            "  - Healthy lifestyle encouragement\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "\n",
            "Lower-risk Example Result:\n",
            "Prediction: Alive\n",
            "Survival Probability: 55.81%\n",
            "Death Probability:    44.19%\n",
            "Risk Level: Moderate Risk\n",
            "Recommendations:\n",
            "  - Lower risk indicated\n",
            "  - Standard treatment protocol\n",
            "  - Regular follow-up (6-12 months)\n",
            "  - Healthy lifestyle encouragement\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "\n",
            "Lower-risk Example Result:\n",
            "Prediction: Alive\n",
            "Survival Probability: 55.81%\n",
            "Death Probability:    44.19%\n",
            "Risk Level: Moderate Risk\n",
            "Recommendations:\n",
            "  - Lower risk indicated\n",
            "  - Standard treatment protocol\n",
            "  - Regular follow-up (6-12 months)\n",
            "  - Healthy lifestyle encouragement\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "\n",
            "Lower-risk Example Result:\n",
            "Prediction: Alive\n",
            "Survival Probability: 55.81%\n",
            "Death Probability:    44.19%\n",
            "Risk Level: Moderate Risk\n",
            "Recommendations:\n",
            "  - Lower risk indicated\n",
            "  - Standard treatment protocol\n",
            "  - Regular follow-up (6-12 months)\n",
            "  - Healthy lifestyle encouragement\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "\n",
            "Higher-risk Example Result:\n",
            "Prediction: Dead\n",
            "Survival Probability: 14.55%\n",
            "Death Probability:    85.45%\n",
            "Risk Level: High Risk\n",
            "Recommendations:\n",
            "  - ‚ö†Ô∏è Higher risk of poor prognosis detected\n",
            "  - üè• Recommend aggressive treatment approach\n",
            "  - üìÖ Frequent follow-up monitoring (every 3-6 months)\n",
            "  - üî¨ Consider additional diagnostic tests\n",
            "  - üë• Multidisciplinary team consultation recommended\n",
            "  - ‚öïÔ∏è Large tumor size - consider neoadjuvant therapy\n",
            "  - üî¨ High-grade tumor - consider adjuvant chemotherapy\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "\n",
            "Higher-risk Example Result:\n",
            "Prediction: Dead\n",
            "Survival Probability: 14.55%\n",
            "Death Probability:    85.45%\n",
            "Risk Level: High Risk\n",
            "Recommendations:\n",
            "  - ‚ö†Ô∏è Higher risk of poor prognosis detected\n",
            "  - üè• Recommend aggressive treatment approach\n",
            "  - üìÖ Frequent follow-up monitoring (every 3-6 months)\n",
            "  - üî¨ Consider additional diagnostic tests\n",
            "  - üë• Multidisciplinary team consultation recommended\n",
            "  - ‚öïÔ∏è Large tumor size - consider neoadjuvant therapy\n",
            "  - üî¨ High-grade tumor - consider adjuvant chemotherapy\n",
            "\n",
            "Options:\n",
            "  1) Enter patient data and predict\n",
            "  2) Use example: Lower risk profile\n",
            "  3) Use example: Higher risk profile\n",
            "  4) Exit\n",
            "Exiting prognosis menu.\n",
            "Exiting prognosis menu.\n"
          ]
        }
      ],
      "source": [
        "# Interactive Menu: Breast Cancer Prognosis Recommendation (RS_A4)\n",
        "# Run cell 1 first. Then run this cell to launch the menu.\n",
        "\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "\n",
        "# --- Helpers ---------------------------------------------------------------\n",
        "\n",
        "def _pick_from_list(name, options, default=None):\n",
        "    options = [str(o) for o in options if pd.notna(o)]\n",
        "    options = sorted(list(dict.fromkeys(options)))  # unique + stable order\n",
        "    if not options:\n",
        "        return input(f\"Enter {name}: \").strip() or (default or '')\n",
        "    preview = \", \".join(options[:10]) + (\" ...\" if len(options) > 10 else \"\")\n",
        "    while True:\n",
        "        raw = input(f\"{name} [{default if default is not None else ''}] (e.g., {preview}): \").strip()\n",
        "        if raw:\n",
        "            return raw\n",
        "        if default is not None:\n",
        "            return default\n",
        "\n",
        "\n",
        "def _prompt_float(name, default):\n",
        "    while True:\n",
        "        raw = input(f\"{name} [{default}]: \").strip()\n",
        "        if raw == '':\n",
        "            return float(default)\n",
        "        try:\n",
        "            return float(raw)\n",
        "        except Exception:\n",
        "            print(\"Enter a number.\")\n",
        "\n",
        "\n",
        "def _prompt_int(name, default):\n",
        "    while True:\n",
        "        raw = input(f\"{name} [{default}]: \").strip()\n",
        "        if raw == '':\n",
        "            return int(default)\n",
        "        try:\n",
        "            return int(raw)\n",
        "        except Exception:\n",
        "            print(\"Enter an integer.\")\n",
        "\n",
        "\n",
        "def _defaults_from_data():\n",
        "    # Prefer df_processed if available, else df\n",
        "    src = None\n",
        "    try:\n",
        "        src = df_processed\n",
        "    except NameError:\n",
        "        try:\n",
        "            src = df\n",
        "        except NameError:\n",
        "            src = None\n",
        "    num_defaults = {}\n",
        "    if isinstance(src, pd.DataFrame):\n",
        "        for col in ['Age','Tumor Size','Regional Node Examined','Reginol Node Positive','Survival Months']:\n",
        "            if col in src.columns:\n",
        "                num_defaults[col] = float(src[col].median())\n",
        "    # categorical defaults: first class from encoders if present\n",
        "    cat_defaults = {}\n",
        "    try:\n",
        "        for col in ['Race','Marital Status','T Stage','N Stage','6th Stage','Grade','A Stage','Estrogen Status','Progesterone Status']:\n",
        "            if col in label_encoders and hasattr(label_encoders[col], 'classes_'):\n",
        "                cat_defaults[col] = label_encoders[col].classes_[0]\n",
        "    except NameError:\n",
        "        pass\n",
        "    return num_defaults, cat_defaults\n",
        "\n",
        "\n",
        "def _options_from_data(col):\n",
        "    # Gather options to help the user pick\n",
        "    if 'label_encoders' in globals() and col in label_encoders and hasattr(label_encoders[col], 'classes_'):\n",
        "        return list(label_encoders[col].classes_)\n",
        "    if 'df' in globals() and isinstance(df, pd.DataFrame) and col in df.columns:\n",
        "        return sorted(df[col].dropna().astype(str).unique().tolist())\n",
        "    return []\n",
        "\n",
        "\n",
        "def _collect_patient_input():\n",
        "    num_defaults, cat_defaults = _defaults_from_data()\n",
        "\n",
        "    # Categorical choices\n",
        "    race = _pick_from_list('Race', _options_from_data('Race'), cat_defaults.get('Race','White'))\n",
        "    marital = _pick_from_list('Marital Status', _options_from_data('Marital Status'), cat_defaults.get('Marital Status','Married (including common law)'))\n",
        "    t_stage = _pick_from_list('T Stage', _options_from_data('T Stage'), cat_defaults.get('T Stage','T1'))\n",
        "    n_stage = _pick_from_list('N Stage', _options_from_data('N Stage'), cat_defaults.get('N Stage','N0'))\n",
        "    sixth = _pick_from_list('6th Stage', _options_from_data('6th Stage'), cat_defaults.get('6th Stage','IIA'))\n",
        "    grade = _pick_from_list('Grade', _options_from_data('Grade'), cat_defaults.get('Grade','Moderate'))\n",
        "    a_stage = _pick_from_list('A Stage', _options_from_data('A Stage'), cat_defaults.get('A Stage','Regional'))\n",
        "    er = _pick_from_list('Estrogen Status', _options_from_data('Estrogen Status'), cat_defaults.get('Estrogen Status','Positive'))\n",
        "    pr = _pick_from_list('Progesterone Status', _options_from_data('Progesterone Status'), cat_defaults.get('Progesterone Status','Positive'))\n",
        "\n",
        "    # Numeric entries\n",
        "    age = _prompt_int('Age', int(num_defaults.get('Age', 55)))\n",
        "    tumor = _prompt_int('Tumor Size (mm)', int(num_defaults.get('Tumor Size', 30)))\n",
        "    nodes_exam = _prompt_int('Regional Node Examined', int(num_defaults.get('Regional Node Examined', 12)))\n",
        "    nodes_pos = _prompt_int('Reginol Node Positive', int(num_defaults.get('Reginol Node Positive', 2)))\n",
        "    surv_months = _prompt_int('Survival Months', int(num_defaults.get('Survival Months', 24)))\n",
        "\n",
        "    patient = {\n",
        "        'Age': age,\n",
        "        'Race': race,\n",
        "        'Marital Status': marital,\n",
        "        'T Stage': t_stage,\n",
        "        'N Stage': n_stage,\n",
        "        '6th Stage': sixth,\n",
        "        'Grade': grade,\n",
        "        'A Stage': a_stage,\n",
        "        'Tumor Size': tumor,\n",
        "        'Estrogen Status': er,\n",
        "        'Progesterone Status': pr,\n",
        "        'Regional Node Examined': nodes_exam,\n",
        "        'Reginol Node Positive': nodes_pos,\n",
        "        'Survival Months': surv_months,\n",
        "    }\n",
        "    return patient\n",
        "\n",
        "\n",
        "def _safe_predict(patient_data):\n",
        "    # Use existing predict_prognosis if available; else fallback\n",
        "    try:\n",
        "        res = predict_prognosis(patient_data, best_model, scaler, X.columns.tolist(), label_encoders)\n",
        "        return res\n",
        "    except Exception as e:\n",
        "        # Fallback: minimal pipeline using encoders and scaler\n",
        "        local = pd.DataFrame([patient_data])\n",
        "        # Encode via label_encoders\n",
        "        if 'label_encoders' in globals():\n",
        "            for col, enc in label_encoders.items():\n",
        "                if col == 'Status':\n",
        "                    continue\n",
        "                if col in local.columns:\n",
        "                    try:\n",
        "                        local[col] = enc.transform(local[col].astype(str))\n",
        "                    except Exception:\n",
        "                        # unseen label -> use first class\n",
        "                        try:\n",
        "                            local[col] = enc.transform([enc.classes_[0]])[0]\n",
        "                        except Exception:\n",
        "                            local[col] = 0\n",
        "        # Ensure all features\n",
        "        for col in X.columns:\n",
        "            if col not in local.columns:\n",
        "                local[col] = 0\n",
        "        local = local[X.columns]\n",
        "        Xs = scaler.transform(local)\n",
        "        pred = best_model.predict(Xs)[0]\n",
        "        proba = best_model.predict_proba(Xs)[0] if hasattr(best_model,'predict_proba') else None\n",
        "        risk = 'Unable to determine'\n",
        "        if proba is not None:\n",
        "            death_prob = float(proba[1])\n",
        "            risk = 'Low Risk' if death_prob < 0.3 else ('Moderate Risk' if death_prob < 0.6 else 'High Risk')\n",
        "        recs = []\n",
        "        if proba is not None and proba[1] > 0.5 or pred == 1:\n",
        "            recs += [\n",
        "                'Higher risk detected; consider aggressive treatment',\n",
        "                'Frequent follow-up (3-6 months)',\n",
        "                'Additional diagnostic tests',\n",
        "                'Multidisciplinary team consultation'\n",
        "            ]\n",
        "        else:\n",
        "            recs += [\n",
        "                'Lower risk indicated',\n",
        "                'Standard treatment protocol',\n",
        "                'Regular follow-up (6-12 months)',\n",
        "                'Healthy lifestyle encouragement'\n",
        "            ]\n",
        "        if 'Tumor Size' in patient_data and patient_data['Tumor Size'] > 50:\n",
        "            recs.append('Large tumor size - consider neoadjuvant therapy')\n",
        "        return {\n",
        "            'prediction': 'Dead' if int(pred) == 1 else 'Alive',\n",
        "            'probability': proba,\n",
        "            'risk_level': risk,\n",
        "            'recommendations': recs\n",
        "        }\n",
        "\n",
        "\n",
        "def launch_prognosis_menu():\n",
        "    print(\"=\"*80)\n",
        "    print(\"BREAST CANCER PROGNOSIS - INTERACTIVE MENU\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nOptions:\")\n",
        "        print(\"  1) Enter patient data and predict\")\n",
        "        print(\"  2) Use example: Lower risk profile\")\n",
        "        print(\"  3) Use example: Higher risk profile\")\n",
        "        print(\"  4) Exit\")\n",
        "        choice = input(\"Select [1-4]: \").strip() or '1'\n",
        "\n",
        "        if choice == '1':\n",
        "            patient = _collect_patient_input()\n",
        "            res = _safe_predict(patient)\n",
        "            print(\"\\nPrediction Result:\")\n",
        "            print(f\"Prediction: {res['prediction']}\")\n",
        "            if res.get('probability') is not None:\n",
        "                print(f\"Survival Probability: {res['probability'][0]:.2%}\")\n",
        "                print(f\"Death Probability:    {res['probability'][1]:.2%}\")\n",
        "            print(f\"Risk Level: {res['risk_level']}\")\n",
        "            print(\"Recommendations:\")\n",
        "            for r in res.get('recommendations', []):\n",
        "                print(f\"  - {r}\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            patient = {\n",
        "                'Age': 48,\n",
        "                'Race': 'White',\n",
        "                'Marital Status': 'Married (including common law)',\n",
        "                'T Stage': 'T1',\n",
        "                'N Stage': 'N0',\n",
        "                '6th Stage': 'IIA',\n",
        "                'Grade': 'Moderate',\n",
        "                'A Stage': 'Regional',\n",
        "                'Tumor Size': 18,\n",
        "                'Estrogen Status': 'Positive',\n",
        "                'Progesterone Status': 'Positive',\n",
        "                'Regional Node Examined': 12,\n",
        "                'Reginol Node Positive': 0,\n",
        "                'Survival Months': 36,\n",
        "            }\n",
        "            res = _safe_predict(patient)\n",
        "            print(\"\\nLower-risk Example Result:\")\n",
        "            print(f\"Prediction: {res['prediction']}\")\n",
        "            if res.get('probability') is not None:\n",
        "                print(f\"Survival Probability: {res['probability'][0]:.2%}\")\n",
        "                print(f\"Death Probability:    {res['probability'][1]:.2%}\")\n",
        "            print(f\"Risk Level: {res['risk_level']}\")\n",
        "            print(\"Recommendations:\")\n",
        "            for r in res.get('recommendations', []):\n",
        "                print(f\"  - {r}\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            patient = {\n",
        "                'Age': 67,\n",
        "                'Race': 'Black',\n",
        "                'Marital Status': 'Single',\n",
        "                'T Stage': 'T3',\n",
        "                'N Stage': 'N2',\n",
        "                '6th Stage': 'IIIB',\n",
        "                'Grade': 'Poorly',\n",
        "                'A Stage': 'Regional',\n",
        "                'Tumor Size': 75,\n",
        "                'Estrogen Status': 'Negative',\n",
        "                'Progesterone Status': 'Negative',\n",
        "                'Regional Node Examined': 20,\n",
        "                'Reginol Node Positive': 6,\n",
        "                'Survival Months': 12,\n",
        "            }\n",
        "            res = _safe_predict(patient)\n",
        "            print(\"\\nHigher-risk Example Result:\")\n",
        "            print(f\"Prediction: {res['prediction']}\")\n",
        "            if res.get('probability') is not None:\n",
        "                print(f\"Survival Probability: {res['probability'][0]:.2%}\")\n",
        "                print(f\"Death Probability:    {res['probability'][1]:.2%}\")\n",
        "            print(f\"Risk Level: {res['risk_level']}\")\n",
        "            print(\"Recommendations:\")\n",
        "            for r in res.get('recommendations', []):\n",
        "                print(f\"  - {r}\")\n",
        "\n",
        "        elif choice == '4':\n",
        "            print(\"Exiting prognosis menu.\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Please select a valid option (1-4).\")\n",
        "\n",
        "# Auto-launch the menu when this cell runs (comment out to disable)\n",
        "launch_prognosis_menu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
